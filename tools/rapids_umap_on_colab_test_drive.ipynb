{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rapids_umap_on_colab_test_drive.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrl1ldzM0bNa",
        "colab_type": "text"
      },
      "source": [
        "# Rapids UMAP on Colab\n",
        "\n",
        "# <img src=\"http://reconstrue.com/assets/images/reconstrue_logo_brandmark.svg\" width=\"42px\" align=\"top\" /> **Reconstrue**\n",
        "\n",
        "## Legal\n",
        "\n",
        "This code is licensed by Reconstrue under the Apache 2.0 License.\n",
        "\n",
        "Reconstrue's work on this started from notebooks in the Rapids' repo, [notebook-contrib](https://github.com/rapidsai/notebooks-contrib) which is licensed licensed under the [Apache License 2.0](https://github.com/rapidsai/notebooks-contrib/blob/branch-0.11/LICENSE). The following two files were used:\n",
        "- [umap_demo.ipynb](https://github.com/rapidsai/notebooks-contrib/blob/branch-0.11/colab_notebooks/cuml/umap_demo.ipynb)\n",
        "- [09_Introduction_to_Dimensionality_Reduction.ipynb](https://github.com/rapidsai/notebooks-contrib/blob/branch-0.11/getting_started_notebooks/intro_tutorials/09_Introduction_to_Dimensionality_Reduction.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "860BsKklOucV",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook exercises Rapids' GPU accelerated UMAP implementation, on Colab. This is just a proof of concept test drive, nothing single-cell specific, nor large datasets. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtBC7XpOiraN",
        "colab_type": "text"
      },
      "source": [
        "## Set up\n",
        "\n",
        "The main tests can be a bit slow. So, here's some switches to control which tests to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YRii5FYeSSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Pre-run config switches\n",
        "\n",
        "# UMAP of iris dataset costs about 10 minutes\n",
        "run_stock_umap = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "run_rapids_umap = True #@param {type:\"boolean\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9WpprEC9XDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_gpu_rapids_friendly():\n",
        "  import sys, os \n",
        "\n",
        "  sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "  os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "  os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "\n",
        "  import pynvml\n",
        "\n",
        "  pynvml.nvmlInit()\n",
        "  handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "  device_name = pynvml.nvmlDeviceGetName(handle)\n",
        "\n",
        "  answer = False\n",
        "  if (device_name == b'Tesla T4') or (device_name == b'Tesla P100-PCIE-16GB'):\n",
        "    answer = True\n",
        "  return answer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6WEEHp5bOAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import IPython \n",
        "\n",
        "def get_audio_file(filename, url):\n",
        "  bells_dest_dir = \"/content/tmp/\"\n",
        "  dest_filename = os.path.join(bells_dest_dir, filename)\n",
        "  if not os.path.exists(bells_dest_dir):\n",
        "    os.mkdir(bells_dest_dir)\n",
        "  response = requests.get(url)\n",
        "  with open(dest_filename, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "  return dest_filename\n",
        "\n",
        "jingle_bell_filename = get_audio_file(\"jingle_bell.mp3\", \"https://www.soundjay.com/misc/bell-ringing-05.mp3\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpbjIpWbfZ0Y",
        "colab_type": "text"
      },
      "source": [
        "## Pre-installed umap-learn\n",
        "\n",
        "The stock UMAP implementation, package umap-learn, comes preinstalled on Colab.\n",
        "\n",
        "This version is already fast because Numba is used. The below tests indicate that Numba is compiling to the GPU or TPU if present (although the TPU has not been put to better effect than the GPU).\n",
        "\n",
        "| Run time | Runtime | Date |\n",
        "|--|--|--|\n",
        "| 0:14:20 | CPU | 2019-12-06 |\n",
        "| 0:06:19 | K80 | 2019-12-06 |\n",
        "| 0:10:52 | K80 | 2019-12-08 |\n",
        "| **0:07:11** | TPU | 2019-12-06 |\n",
        "\n",
        "These tests were repeated a few times. Times were all within about 15 seconds of each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DclxEqzbfVOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Default Colab install of UMAP\n",
        "!pip show umap-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw8LjQs2Nh6P",
        "colab_type": "text"
      },
      "source": [
        "### MNIST by umap-learn\n",
        "\n",
        "Via [UMAP on the MNIST Digits dataset](https://umap-learn.readthedocs.io/en/latest/auto_examples/plot_mnist_example.html#sphx-glr-auto-examples-plot-mnist-example-py)\n",
        "\n",
        "Iris data loaded by [fetch_openml](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf6gd_odNgtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import umap\n",
        "from sklearn.datasets import fetch_openml\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "sns.set(context=\"notebook\", style=\"dark\")\n",
        "\n",
        "def exercise_stock_umap():\n",
        "  start_time = time.time()\n",
        "  print(\"Start time:  %s\\n\" % datetime.datetime.now())\n",
        "\n",
        "  mnist = fetch_openml('mnist_784', version=1)\n",
        "\n",
        "  reducer = umap.UMAP(random_state=42, verbose=True)\n",
        "  embedding = reducer.fit_transform(mnist.data)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(12, 10))\n",
        "  color = mnist.target.astype(int)\n",
        "  plt.scatter(\n",
        "    embedding[:, 0], embedding[:, 1], c=color, cmap=\"Spectral\", s=0.1\n",
        "  )\n",
        "  plt.setp(ax, xticks=[], yticks=[])\n",
        "  plt.title(\"MNIST by stock UMAP\", fontsize=18)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Run time: %s\" % datetime.timedelta(seconds=round(time.time()-start_time)))\n",
        "\n",
        "if run_stock_umap:\n",
        "  exercise_stock_umap()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEHm2frvfpw2",
        "colab_type": "text"
      },
      "source": [
        "## Rapids UMAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4wTLYaPx443",
        "colab_type": "text"
      },
      "source": [
        "### Detect GPU\n",
        "\n",
        "On Colab, you have to explicitly request a GPU. As of late 2019, there are four that have been seen recently.\n",
        "\n",
        "These work with Rapids:\n",
        "- Tesla P100\n",
        "- Tesla T4\n",
        "\n",
        "These do not:\n",
        "- Tesla P4\n",
        "- Tesla K80\n",
        "\n",
        "Check to maker sure a compatible GPU has been allocated (after, of course, being requested)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7IZiscfxzDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgQi9QYRx-2Y",
        "colab_type": "text"
      },
      "source": [
        "### Detect TPU\n",
        "\n",
        "I doubt Rapids works with TPU. TPUs are Google hardware; Rapids is Nvidia software.\n",
        "\n",
        "But stock UMAP uses Numba to JIT, so perhaps Numba can compile to TPU. [Test results show TPU is faster than CPU but roughly same speed as GPU. More testing needed.]\n",
        "\n",
        "Note that [Colab can deploy Tensorflow 1 or 2](https://colab.research.google.com/notebooks/tensorflow_version.ipynb#scrollTo=NeWVBhf1VxlH) and we want 2.\n",
        "\n",
        "**TODO:** This would be a good snippet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2CDK2RPyC8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Colab has two flavors of TensorFlow: TF 1.x & 2.x. Be explicit to suppress a warning. \n",
        "try:\n",
        "  # %tensorflow_version is a Colab-only thing \n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  print(\"TensorFlow 2.x does not seem to be available\")\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# Alternatively, similar in JSON\n",
        "#device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDpPVtl2yKQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; Request a TPU runtime in the Runtime menu')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1ViGI1EyIpD",
        "colab_type": "text"
      },
      "source": [
        "Complaints of NVIDIA-SMI failing to communicate with NVIDIA driver means there is no GPU. A GPU can be requested in the `Runtime` menu via 'Change runtime type'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MIpHYhJP7sGy"
      },
      "source": [
        "### cuML's UMAP docs\n",
        "\n",
        "UMAP is a dimensionality reduction algorithm which performs non-linear dimension reduction. \n",
        "- It can also be used for visualization of the dataset. \n",
        "\n",
        "The UMAP model implemented in cuml allows the user to set the following parameter values:\n",
        "1.\t`n_neighbors`: number of neighboring samples used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved (default = 15)\n",
        "2.\t`n_components`: the dimension of the space to embed into (default = 2)\n",
        "3.\t`n_epochs`: number of training epochs to be used in optimizing the low dimensional embedding (default = None)\n",
        "4.\t`learning_rate`: initial learning rate for the embedding optimization (default = 1.0)\n",
        "5.\t`init`: the low dimensional embedding to use: a. 'spectral': use a spectral embedding of the fuzzy 1-skeleton b. 'random': assign initial embedding positions at random (default = 'spectral')\n",
        "6.\t`min_dist`: the minimum distance that should be present between embedded points (default = 0.1)\n",
        "7.\t`spread`: determines how clustered the embedded points will be (default = 1.0)\n",
        "8.\t`set_op_mix_ratio`: is the ratio of pure fuzzy union to intersection. If the value is 1.0 then it will be a pure fuzzy union and for the value of 0.0 it will be a pure fuzzy interpolation (default = 1.0)\n",
        "9.\t`local_connectivity`: number of nearest neighbors that should be assumed to be connected at a local level. It should be not more than the local intrinsic dimension of the manifold (default = 1)\n",
        "10.\t`repulsion_strength`: weighting applied to negative samples in low dimensional embedding optimization. Values > 1 implements a higher negative value to the samples (default = 1.0)\n",
        "11.\t`negative_sample_rate`: the rate at which the negative samples should be selected per positive sample during the optimization process (default = 5)\n",
        "12.\t`transform_queue_size`: embedding new points using a trained model_ will control how aggressively to search for nearest neighbors (default = 4.0)\n",
        "13.\t`verbose`: bool (default False)\n",
        "\n",
        "The cuml implemetation of the UMAP model has the following functions that one can run:\n",
        "1.\t`fit`: it fits the dataset into an embedded space\n",
        "2.\t`fit_transform`: it fits the dataset into an embedded space and returns the transformed output\n",
        "3.\t`transform`: it transforms the dataset into an existing embedded space and returns the low dimensional output\n",
        "\n",
        "The model accepts only numpy arrays or cudf dataframes as the input. \n",
        "- In order to convert your dataset to cudf format please read the cudf [documentation](https://rapidsai.github.io/projects/cudf/en/latest/) \n",
        "- For additional information on the UMAP model please refer to the cuml [UMAP documentation](https://rapidsai.github.io/projects/cuml/en/0.6.0/api.html#cuml.UMAP) \n",
        "- This setup may take a few minutes\n",
        "- Long output (output display removed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slurdJ29e0Kx",
        "colab_type": "text"
      },
      "source": [
        "### Install take 1\n",
        "\n",
        "Rapids says to download [rapids-colab.sh](https://raw.githubusercontent.com/rapidsai/notebooks-contrib/master/utils/rapids-colab.sh) and run it through bash. That script asks the user what version they want. We want `0.11`. So shortcircuit the asking and just say `0.11`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88pWtyLPlB4K",
        "colab_type": "text"
      },
      "source": [
        "This installs miniconda (the installer-only, slimmer install of Anaconda), then conda installs dask and rapids, so heavy.\n",
        "\n",
        "https://raw.githubusercontent.com/rapidsai/notebooks-contrib/master/utils/rapids-colab.sh\n",
        "\n",
        "**TODO: There's got to be a way to check if Rapids already installed, and bypass if so (to avoid reinstalls after inactivity disconnects).\n",
        "\n",
        "Dask comes pre-installed but rapids-colab.sh uninstalls and then reinstalls (versioning?).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oay5-tjjCD16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is env-eval.py, which fails from a %%bash cell so just dropped it into a cell here:\n",
        "import sys, os \n",
        "\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "\n",
        "import pynvml\n",
        "\n",
        "pynvml.nvmlInit()\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "device_name = pynvml.nvmlDeviceGetName(handle)\n",
        "\n",
        "if (device_name == b'Tesla T4') or (device_name == b'Tesla P100-PCIE-16GB'):\n",
        "  print('***********************************************************************')\n",
        "  print('Woo! Your instance has the right kind of GPU, a '+ str(device_name)[1:]+'!')\n",
        "  print('***********************************************************************')\n",
        "  print()\n",
        "else:\n",
        "  raise Exception(\"\"\"\n",
        "    Unfortunately Colab didn't give you a T4 or P100 GPU.\n",
        "    \n",
        "    Make sure you've configured Colab to request a GPU instance type.\n",
        "    \n",
        "    If you get a K80 GPU, try Runtime -> Reset all runtimes...\n",
        "  \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6eK8lvy_5LU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "# Tell the script we want 0.11\n",
        "RAPIDS_VERSION=0.11\n",
        "\n",
        "if [ ! -f Miniconda3-4.5.4-Linux-x86_64.sh ]; then\n",
        "    echo \"Removing conflicting packages, will replace with RAPIDS compatible versions\"\n",
        "    # remove existing xgboost and dask installs\n",
        "    pip uninstall -y xgboost dask distributed\n",
        "\n",
        "    # intall miniconda\n",
        "    echo \"Installing conda\"\n",
        "    wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "    chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "    bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "    \n",
        "    if [ $RAPIDS_VERSION == 0.11 ] ;then\n",
        "    echo \"Installing RAPIDS $RAPIDS_VERSION packages from the nightly release channel\"\n",
        "    echo \"Please standby, this will take a few minutes...\"\n",
        "    # install RAPIDS packages\n",
        "        conda install -y --prefix /usr/local \\\n",
        "                -c rapidsai-nightly/label/xgboost -c rapidsai-nightly -c nvidia -c conda-forge \\\n",
        "                python=3.6 cudatoolkit=10.1 \\\n",
        "                cudf=$RAPIDS_VERSION cuml cugraph gcsfs pynvml cuspatial \\\n",
        "                dask-cudf \\\n",
        "                xgboost\n",
        "        # check to make sure that pyarrow is running the right version (0.15) for v0.11 or later\n",
        "        wget -nc https://github.com/rapidsai/notebooks-contrib/raw/master/utils/update_pyarrow.py\n",
        "\n",
        "    else\n",
        "        echo \"Installing RAPIDS $RAPIDS_VERSION packages from the stable release channel\"\n",
        "        echo \"Please standby, this will take a few minutes...\"\n",
        "        # install RAPIDS packages\n",
        "        conda install -y --prefix /usr/local \\\n",
        "            -c rapidsai/label/xgboost -c rapidsai -c nvidia -c conda-forge \\\n",
        "            python=3.6 cudatoolkit=10.1 \\\n",
        "            cudf=$RAPIDS_VERSION cuml cugraph cuspatial gcsfs pynvml \\\n",
        "            dask-cudf \\\n",
        "            xgboost\n",
        "    fi\n",
        "      \n",
        "    echo \"Copying shared object files to /usr/lib\"\n",
        "    # copy .so files to /usr/lib, where Colab's Python looks for libs\n",
        "    cp /usr/local/lib/libcudf.so /usr/lib/libcudf.so\n",
        "    cp /usr/local/lib/librmm.so /usr/lib/librmm.so\n",
        "    cp /usr/local/lib/libnccl.so /usr/lib/libnccl.so\n",
        "fi\n",
        "\n",
        "echo \"\"\n",
        "echo \"*********************************************\"\n",
        "echo \"Your Google Colab instance is RAPIDS ready!\"\n",
        "echo \"*********************************************\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R3dg3H12-WMz",
        "colab": {}
      },
      "source": [
        "# TODO: Kill\n",
        "# This was before Rapids 0.11\n",
        "#!wget -nc https://github.com/rapidsai/notebooks-extended/raw/master/utils/rapids-colab.sh\n",
        "#!bash rapids-colab.sh\n",
        "#\n",
        "#import sys, os\n",
        "#\n",
        "#sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "#os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "#os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mHh46IYV71b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!RAPID_VERSION=0.11\n",
        "#!wget -nc https://raw.githubusercontent.com/rapidsai/notebooks-contrib/master/utils/rapids-colab.sh\n",
        "#!bash rapids-colab.sh\n",
        "#\n",
        "#import sys, os\n",
        "#dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\n",
        "#sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\n",
        "#sys.path\n",
        "#if os.path.exists('update_pyarrow.py'): ## Only exists if RAPIDS version is 0.11 or higher\n",
        "#  exec(open('update_pyarrow.py').read(), globals())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjKf4LMnXxq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo RAPID_VERSION=$RAPIDS_VERSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYZyuWpriebo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDOj2oVCURFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uEZH1MsJWUw",
        "colab_type": "text"
      },
      "source": [
        "### Install Take 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwqfhpI6JZj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install RAPIDS\n",
        "!wget -nc https://raw.githubusercontent.com/rapidsai/notebooks-contrib/890b04ed8687da6e3a100c81f449ff6f7b559956/utils/rapids-colab.sh\n",
        "!bash rapids-colab.sh\n",
        "\n",
        "import sys, os\n",
        "\n",
        "dist_package_index = sys.path.index(\"/usr/local/lib/python3.6/dist-packages\")\n",
        "sys.path = sys.path[:dist_package_index] + [\"/usr/local/lib/python3.6/site-packages\"] + sys.path[dist_package_index:]\n",
        "sys.path\n",
        "if os.path.exists('update_pyarrow.py'): ## This file only exists if you're using RAPIDS version 0.11 or higher\n",
        "  exec(open(\"update_pyarrow.py\").read(), globals())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iKNf2S0jrk2",
        "colab_type": "text"
      },
      "source": [
        "### Install Take 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHsCoqeorfx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi --list-gpus\n",
        "print('Is current GPU Rapids friendly? %r' % is_gpu_rapids_friendly())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyBDB5VYztYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmB7qKItzuGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm env-check.py\n",
        "!rm Miniconda3-4.5.4-Linux-x86_64.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyUPzeQQ2hb_",
        "colab_type": "text"
      },
      "source": [
        "The install process calls for env-check.py to be run. The following does that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHv5ozWv1-y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is env-check.py, which needs to run for a Python shell, not a %%bash cell else pynvml not found\n",
        "import sys, os \n",
        "\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "\n",
        "import pynvml\n",
        "\n",
        "pynvml.nvmlInit()\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "device_name = pynvml.nvmlDeviceGetName(handle)\n",
        "\n",
        "print('Detected GPU: %s' % device_name.decode(\"utf-8\"))\n",
        "\n",
        "if (device_name == b'Tesla T4') or (device_name == b'Tesla P100-PCIE-16GB'):\n",
        "  print('This Colab VM has a Rapids compatible GPU: ' + str(device_name)[1:])\n",
        "else:\n",
        "  print('This Colab VM does NOT have a Rapids compatible GPU (need a Tesla T4 or P100).')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPv_DPfyjuLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "#!/bin/bash\n",
        "\n",
        "set -eu\n",
        "\n",
        "# fails to find pynvml:\n",
        "#wget -nc --show-progress https://github.com/rapidsai/notebooks-contrib/raw/master/utils/env-check.py\n",
        "#echo \"Checking for GPU type:\"\n",
        "#python env-check.py\n",
        "\n",
        "# TODO: staying with 0.10 b/c 0.11 gets complicated, seemingly. Wait until it's final then 0.11\n",
        "RAPIDS_VERSION=0.10\n",
        "if [ ! -f Miniconda3-4.5.4-Linux-x86_64.sh ]; then\n",
        "    # Note: this echo will not show up in cell output for a while. Flushable?\n",
        "    echo \"Removing conflicting packages, will replace with RAPIDS compatible versions\"\n",
        "    # remove existing xgboost and dask installs\n",
        "    pip uninstall -y xgboost dask distributed\n",
        "\n",
        "    # intall miniconda\n",
        "    echo \"Installing conda\"\n",
        "    wget -nc --show-progress https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "    chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "    bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "    \n",
        "    if [ $RAPIDS_VERSION == 0.11 ] ;then\n",
        "    echo \"Installing RAPIDS $RAPIDS_VERSION packages from the nightly release channel\"\n",
        "    echo \"Please standby, this will take a few minutes...\"\n",
        "    # install RAPIDS packages\n",
        "        conda install -y --prefix /usr/local \\\n",
        "                -c rapidsai-nightly/label/xgboost -c rapidsai-nightly -c nvidia -c conda-forge \\\n",
        "                python=3.6 cudatoolkit=10.1 \\\n",
        "                cudf=$RAPIDS_VERSION cuml cugraph gcsfs pynvml cuspatial \\\n",
        "                dask-cudf \\\n",
        "                xgboost\n",
        "        # check to make sure that pyarrow is running the right version (0.15) for v0.11 or later\n",
        "        wget -nc https://github.com/rapidsai/notebooks-contrib/raw/master/utils/update_pyarrow.py\n",
        "\n",
        "    else\n",
        "        echo \"Installing RAPIDS $RAPIDS_VERSION packages from the stable release channel\"\n",
        "        echo \"Please standby, this will take a few minutes...\"\n",
        "        # install RAPIDS packages\n",
        "        conda install -y --prefix /usr/local \\\n",
        "            -c rapidsai/label/xgboost -c rapidsai -c nvidia -c conda-forge \\\n",
        "            python=3.6 cudatoolkit=10.1 \\\n",
        "            cudf=$RAPIDS_VERSION cuml cugraph cuspatial gcsfs pynvml \\\n",
        "            dask-cudf \\\n",
        "            xgboost\n",
        "    fi\n",
        "      \n",
        "    echo \"Copying shared object files to /usr/lib\"\n",
        "    # copy .so files to /usr/lib, where Colab's Python looks for libs\n",
        "    cp /usr/local/lib/libcudf.so /usr/lib/libcudf.so\n",
        "    cp /usr/local/lib/librmm.so /usr/lib/librmm.so\n",
        "    cp /usr/local/lib/libnccl.so /usr/lib/libnccl.so\n",
        "fi\n",
        "\n",
        "echo \"\"\n",
        "echo \"This Google Colab instance is RAPIDS ready.\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBzJDKPDhFcD",
        "colab_type": "text"
      },
      "source": [
        "### Install Take 4\n",
        "\n",
        "This moves [rapids-colab.sh](https://raw.githubusercontent.com/rapidsai/notebooks-contrib/890b04ed8687da6e3a100c81f449ff6f7b559956/utils/rapids-colab.sh) from a bash cell to a Pythoh cell, which has better progressive feedback output UI.\n",
        "\n",
        "These conda installs are annoyingly [slow](https://github.com/reconstrue/single_cell_on_colab/issues/59)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yC3KR4AhTLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def install_take_4():\n",
        "  RAPIDS_VERSION='0.10'\n",
        "   \n",
        "  if not os.path.exists('/contents/Miniconda3-4.5.4-Linux-x86_64.sh'):\n",
        "    print('Removing conflicting packages, will replace with RAPIDS compatible versions')\n",
        "\n",
        "    # remove existing xgboost and dask installs\n",
        "    !pip uninstall -y xgboost dask distributed\n",
        "\n",
        "    # intall miniconda\n",
        "    print('Installing conda')\n",
        "    !wget -nc --show-progress https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "    !chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "    !bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "    \n",
        "    if RAPIDS_VERSION == '0.11':\n",
        "      print('Installing RAPIDS %s packages from the nightly release channel' % RAPIDS_VERSION)\n",
        "      print('Please standby, this will take a few minutes...')\n",
        "      # install RAPIDS packages\n",
        "      !conda install -y --prefix /usr/local -c rapidsai-nightly/label/xgboost -c rapidsai-nightly -c nvidia -c conda-forge python=3.6 cudatoolkit=10.1 cudf=$RAPIDS_VERSION cuml cugraph gcsfs pynvml cuspatial dask-cudf xgboost\n",
        "      # check to make sure that pyarrow is running the right version (0.15) for v0.11 or later\n",
        "      !wget -nc https://github.com/rapidsai/notebooks-contrib/raw/master/utils/update_pyarrow.py\n",
        "    else:\n",
        "      print('Installing RAPIDS %s packages from the nightly release channel' % RAPIDS_VERSION)\n",
        "      print('Please standby, this will take a few minutes...')\n",
        "      # install RAPIDS packages\n",
        "      !conda install -y --prefix /usr/local -c rapidsai/label/xgboost -c rapidsai -c nvidia -c conda-forge python=3.6 cudatoolkit=10.1 cudf=$RAPIDS_VERSION cuml cugraph cuspatial gcsfs pynvml dask-cudf xgboost\n",
        "      \n",
        "    print('Copying shared object files to /usr/lib')\n",
        "    # copy .so files to /usr/lib, where Colab's Python looks for libs\n",
        "    !cp /usr/local/lib/libcudf.so /usr/lib/libcudf.so\n",
        "    !cp /usr/local/lib/librmm.so /usr/lib/librmm.so\n",
        "    !cp /usr/local/lib/libnccl.so /usr/lib/libnccl.so\n",
        "\n",
        "\n",
        "    import sys, os\n",
        "    dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\n",
        "    sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\n",
        "\n",
        "install_take_4()\n",
        "\n",
        "IPython.display.Audio(jingle_bell_filename, autoplay=True)\n",
        "print('This Google Colab instance is ready for RAPIDS')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BClOq3S_diFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -lh /usr/lib/libcudf.so"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsKMb_yWd4LG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# without this cudf not findable\n",
        "import sys, os\n",
        "dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\n",
        "sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\n",
        "sys.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0SRYgBbzYcu",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YUWGkOZZ7sG0",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold.t_sne import trustworthiness\n",
        "\n",
        "import cudf\n",
        "from cuml.manifold.umap import UMAP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o9KocJ_n7sG4"
      },
      "source": [
        "@# Running cuml's UMAP model on blobs dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Si3IagNP7sG6",
        "colab": {}
      },
      "source": [
        "# create a blobs dataset with 500 samples and 10 features each\n",
        "data, labels = datasets.make_blobs(\n",
        "    n_samples=500, n_features=10, centers=5)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MRvCZBWm-H2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using the cuml UMAP algorithm to reduce the features of the dataset and store\n",
        "embedding = UMAP().fit_transform(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek18ea8Tm4Lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# calculate the score of the results obtained using cuml's algorithm and sklearn kmeans\n",
        "score = adjusted_rand_score(labels,\n",
        "            KMeans(5).fit_predict(embedding))\n",
        "print(score) # should equal 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KArSMv1azBt6",
        "colab_type": "text"
      },
      "source": [
        "**Ring a bell at end of Set up**\n",
        "\n",
        "The above install can take a bit, and will have to be done once every 12 hours.\n",
        "\n",
        "Here's a page with a list of free bells sounds: [Bell Sound Effects](https://www.soundjay.com/bell-sound-effect.html). One of those will do as an alert that the boring prelude is over."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9H4cAXbzJKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import IPython\n",
        "\n",
        "# bell_src_10_sec = \"https://www.soundjay.com/misc/bell-ring-01.mp3\"\n",
        "bell_src = \"https://www.soundjay.com/misc/bell-ringing-05.mp3\"\n",
        "bell_dest = \"/content/bell.mp3\"\n",
        "\n",
        "response = requests.get(bell_src)\n",
        "open(bell_dest, 'wb').write(response.content)\n",
        "\n",
        "IPython.display.Audio(bell_dest, autoplay=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EWRiph717sHJ"
      },
      "source": [
        "## Exercise cuml's UMAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OdCayMII7sHK",
        "colab": {}
      },
      "source": [
        "# load the iris dataset from sklearn and extract the required information\n",
        "iris = datasets.load_iris()\n",
        "data = iris.data\n",
        "print(iris.DESCR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bBU1Zcrb7sHP",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# define the cuml UMAP model and use fit_transform function to obtain the low dimensional output of the input dataset\n",
        "embedding = UMAP(\n",
        "    n_neighbors=10, min_dist=0.01,  init=\"random\"\n",
        ").fit_transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNWLwDm87sHS",
        "colab": {}
      },
      "source": [
        "# calculate the trust worthiness of the results obtaind from the cuml UMAP\n",
        "trust = trustworthiness(iris.data, embedding, 10)\n",
        "print(trust)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ify4jpTG7sHW",
        "colab": {}
      },
      "source": [
        "# create a selection variable which will have 75% True and 25% False values. The size of the selection variable is 150\n",
        "iris_selection = np.random.choice(\n",
        "    [True, False], 150, replace=True, p=[0.10, 0.90])\n",
        "# create an iris dataset using the selection variable\n",
        "data = iris.data[iris_selection]\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hcSaciYm7sHb",
        "colab": {}
      },
      "source": [
        "# create a cuml UMAP model \n",
        "fitter = UMAP(n_neighbors=10, min_dist=0.01, verbose=False)\n",
        "# fit the data created the selection variable to the cuml UMAP model created (fitter)\n",
        "fitter.fit(data)\n",
        "# create a new iris dataset by inverting the values of the selection variable (ie. 75% False and 25% True values) \n",
        "new_data = iris.data[~iris_selection]\n",
        "# transform the new data using the previously created embedded space\n",
        "embedding = fitter.transform(new_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l8Xfz80-7sHg",
        "colab": {}
      },
      "source": [
        "# calculate the trustworthiness score for the new data created (new_data)\n",
        "trust = trustworthiness(new_data, embedding, 10)\n",
        "print(trust)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n93nDiCIdP1u",
        "colab_type": "text"
      },
      "source": [
        "And that's where the first notebook ended, without any viz :("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-086eKTCR_fE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(iris)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaEE0K2LPxhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(embedding))\n",
        "#print(embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq5aZ7AHIstb",
        "colab_type": "text"
      },
      "source": [
        "### Continuing to viz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFEecxknIsRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: not working yet:\n",
        "\n",
        "# embedding is the final thing produces int umap_demo.ipynb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "colors = ['blue', 'orange', 'green', 'red', 'purple', \n",
        "          'brown', 'pink', 'gray', 'olive', 'cyan']\n",
        "colors = ['tab:' + color for color in colors]\n",
        "\n",
        "# create figure\n",
        "figure = plt.figure()\n",
        "axis = figure.add_subplot(111)\n",
        "\n",
        "for i in range(4):\n",
        "    # WANT: \n",
        "    mask = iris.target[~iris_selection] == i\n",
        "    #mask = y == i\n",
        "    print(len(mask))\n",
        "    axis.scatter(embedding[mask, 0], embedding[mask, 1], \n",
        "                 c=colors[i], label=str(i))\n",
        "    #axis.scatter(embedding[:, 0], embedding[:, 1], \n",
        "    #             c=colors[i], label=str(i))\n",
        "axis.set_title('UMAP by Rapids')\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQPq3n-rogsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(iris.target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENtUkyKbc5I8",
        "colab_type": "text"
      },
      "source": [
        "## Stuff from Intro to DR notebook\n",
        "\n",
        "Repo `rapidsai/notebooks-contrib` has [09_Introduction_to_Dimensionality_Reduction.ipynb](https://github.com/rapidsai/notebooks-contrib/blob/branch-0.11/getting_started_notebooks/intro_tutorials/09_Introduction_to_Dimensionality_Reduction.ipynb), which does have a viz or two.\n",
        "\n",
        "First notice the distinct inports. In umap_demo.ipynb:\n",
        "```\n",
        "from cuml.manifold.umap import UMAP\n",
        "```\n",
        "In 09_Introduction_to_Dimensionality_Reduction.ipynb:\n",
        "```\n",
        "from cuml import UMAP as UMAP_GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b7YAEnDvsD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np; print('NumPy Version:', np.__version__)\n",
        "import sklearn; print('Scikit-Learn Version:', sklearn.__version__)\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "\n",
        "digits = load_digits()\n",
        "X, y = digits['data'], digits['target']\n",
        "X, y = X.astype(np.float32), y.astype(np.float32)\n",
        "print('X: ', X.shape, X.dtype, 'y: ', y.shape, y.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec5dvVNYwmLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create figure\n",
        "import matplotlib.pyplot as plt\n",
        "figure = plt.figure()\n",
        "f, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "\n",
        "i = 0\n",
        "for row in axes:\n",
        "    for axis in row:\n",
        "        axis.imshow(X[i].reshape(8, 8), cmap='gray')\n",
        "        axis.set_title('Class: ' + str(int(y[i])))\n",
        "        i += 1\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PUQDRbH16tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_df = pd.DataFrame(X)\n",
        "X_df.columns = ['feature_' + str(i) for i in range(X_df.shape[1])]\n",
        "X_cudf = cudf.DataFrame.from_pandas(X_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn3tZnuzwuE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cuml import UMAP as UMAP_GPU\n",
        "umap_gpu = UMAP_GPU(n_neighbors=10, n_components=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJTpjYBPwzwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "components_gpu = umap_gpu.fit_transform(X_cudf).to_pandas().values\n",
        "components_gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5AD3vWRed-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "colors = ['blue', 'orange', 'green', 'red', 'purple', \n",
        "          'brown', 'pink', 'gray', 'olive', 'cyan']\n",
        "colors = ['tab:' + color for color in colors]\n",
        "\n",
        "# create figure\n",
        "figure = plt.figure()\n",
        "axis = figure.add_subplot(111)\n",
        "\n",
        "for i in range(10):\n",
        "    mask = y == i\n",
        "    axis.scatter(components_gpu[mask, 0], components_gpu[mask, 1], \n",
        "                 c=colors[i], label=str(i))\n",
        "axis.set_title('UMAP (gpu)')\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifv-Pf_Djm2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}